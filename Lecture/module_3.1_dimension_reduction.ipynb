{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbebdc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Load required packages\n",
    "options(dplyr.summarise.inform = FALSE)\n",
    "library(tidyverse)\n",
    "library(mlba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bf048c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Data Summaries ‚Äî Understanding Your Data\n",
    "\n",
    "### üè¢ Business Context\n",
    "\n",
    "Before any analysis, you must **know your data**. Summary statistics answer critical questions:\n",
    "\n",
    "| Stakeholder Question | Statistic | Business Insight |\n",
    "|---------------------|-----------|------------------|\n",
    "| \"What's typical?\" | Mean, Median | Central tendency, expected value |\n",
    "| \"How variable is it?\" | SD, Range | Risk, volatility, consistency |\n",
    "| \"Are there extremes?\" | Min, Max | Outliers, edge cases |\n",
    "| \"Is data complete?\" | Missing count | Data quality issues |\n",
    "\n",
    "### Example 1: Boston House Prices\n",
    "\n",
    "We'll analyze the Boston Housing dataset ‚Äî used by real estate companies, banks, and urban planners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da42288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.housing.df <- mlba::BostonHousing\n",
    "head(boston.housing.df, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eb664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(boston.housing.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c17629",
   "metadata": {},
   "source": [
    "### üìã Interpreting `summary()` Output\n",
    "\n",
    "**For each variable, you see:**\n",
    "- **Min/Max**: Range of values (detect outliers)\n",
    "- **1st Quartile (Q1)**: 25% of values are below this\n",
    "- **Median**: Middle value (50th percentile) ‚Äî robust to outliers\n",
    "- **Mean**: Average ‚Äî sensitive to extreme values\n",
    "- **3rd Quartile (Q3)**: 75% of values are below this\n",
    "\n",
    "**Business insight**: If Mean >> Median ‚Üí right-skewed (few very high values). Common in income, property values.\n",
    "\n",
    "### Computing Individual Statistics\n",
    "\n",
    "For detailed analysis of a single variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca4e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean, standard dev., min, max, median, length, and missing values of CRIM\n",
    "mean(boston.housing.df$CRIM)\n",
    "sd(boston.housing.df$CRIM)\n",
    "min(boston.housing.df$CRIM)\n",
    "max(boston.housing.df$CRIM)\n",
    "median(boston.housing.df$CRIM)\n",
    "length(boston.housing.df$CRIM)\n",
    "\n",
    "# find the number of missing values of variable CRIM\n",
    "sum(is.na(boston.housing.df$CRIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87f1dae",
   "metadata": {},
   "source": [
    "### üìã Understanding Standard Deviation (SD)\n",
    "\n",
    "**SD** measures **spread** or **variability**:\n",
    "- Low SD ‚Üí Values cluster tightly around mean (consistent, predictable)\n",
    "- High SD ‚Üí Values widely dispersed (high variability, risk)\n",
    "\n",
    "**Business example**: \n",
    "- Product quality with SD = 0.1 ‚Üí Very consistent\n",
    "- Stock returns with SD = 30% ‚Üí Very volatile (risky)\n",
    "\n",
    "### Computing Statistics for All Variables\n",
    "\n",
    "Create a comprehensive summary table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a3af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean, standard dev., min, max, median, length, and missing values for all variables\n",
    "data.frame(mean=sapply(boston.housing.df, mean),\n",
    "           sd=sapply(boston.housing.df, sd),\n",
    "           min=sapply(boston.housing.df, min),\n",
    "           max=sapply(boston.housing.df, max),\n",
    "           median=sapply(boston.housing.df, median),\n",
    "           length=sapply(boston.housing.df, length),\n",
    "           miss.val=sapply(boston.housing.df,\n",
    "                           function(x) sum(length(which(is.na(x))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfe71b8",
   "metadata": {},
   "source": [
    "### üìã How to Use This Summary Table\n",
    "\n",
    "**For each row (variable), check:**\n",
    "1. **miss.val**: Any missing values? (Needs imputation?)\n",
    "2. **min/max**: Extreme values? (Outliers? Data errors?)\n",
    "3. **sd**: High variability? (May dominate model if not scaled)\n",
    "4. **mean vs. median**: Large difference? (Skewed distribution?)\n",
    "\n",
    "### Correlation Matrix\n",
    "\n",
    "Understand relationships between variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e630786",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(cor(boston.housing.df),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab4220",
   "metadata": {},
   "source": [
    "### üìã Interpreting Correlations\n",
    "\n",
    "| Correlation | Interpretation | Action |\n",
    "|-------------|----------------|--------|\n",
    "| **r ‚âà +1.0** | Perfect positive relationship | Variables are redundant |\n",
    "| **r ‚âà +0.7 to +0.9** | Strong positive | Consider removing one (multicollinearity) |\n",
    "| **r ‚âà 0** | No linear relationship | Variables are independent |\n",
    "| **r ‚âà -0.7 to -1.0** | Strong negative | Inverse relationship |\n",
    "\n",
    "**Business insight**: If two variables correlate at r > 0.9, they measure nearly the same thing. Keep only one to avoid redundancy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375da163",
   "metadata": {},
   "source": [
    "## Part 2: Aggregation and Pivot Tables\n",
    "\n",
    "### üè¢ Business Context: Slicing and Dicing Data\n",
    "\n",
    "Aggregation answers questions like:\n",
    "- \"What's the average sale price **by region**?\"\n",
    "- \"How does customer satisfaction vary **by product and store**?\"\n",
    "- \"What are total revenues **by quarter and product line**?\"\n",
    "\n",
    "### Frequency Tables\n",
    "\n",
    "Count observations in each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6019d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "table(boston.housing.df$CHAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb12260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidyverse version\n",
    "boston.housing.df %>% count(CHAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374a3b83",
   "metadata": {},
   "source": [
    "### üìã Interpreting Frequency Tables\n",
    "\n",
    "**CHAS** indicates whether the tract bounds the Charles River:\n",
    "- **0**: Does not bound river (majority)\n",
    "- **1**: Bounds river (minority)\n",
    "\n",
    "**Business use**: Check for class imbalance before modeling (remember Module 1.1!).\n",
    "\n",
    "### Creating Bins for Continuous Variables\n",
    "\n",
    "Convert continuous data into categories for easier interpretation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebd8d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bins of size 1 for number of rooms (RM)\n",
    "boston.housing.df <- boston.housing.df %>%\n",
    "  mutate(RM.bin = cut(RM, c(1:9), labels=FALSE))\n",
    "\n",
    "head(boston.housing.df %>% select(RM, RM.bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5edfc2",
   "metadata": {},
   "source": [
    "### Two-Way Aggregation: Pivot Tables\n",
    "\n",
    "Compute averages across multiple dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f89ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the average of MEDV by (binned) RM and CHAS\n",
    "# in aggregate() use the argument by= to define the list of aggregating variables,\n",
    "# and FUN= as an aggregating function.\n",
    "aggregate(boston.housing.df$MEDV, by=list(RM=boston.housing.df$RM.bin,\n",
    "          CHAS=boston.housing.df$CHAS), FUN=mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e041b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidyverse version (cleaner syntax)\n",
    "boston.housing.df %>%\n",
    "  group_by(RM.bin, CHAS) %>%\n",
    "  summarise(mean(MEDV))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b258962",
   "metadata": {},
   "source": [
    "### üìã Interpreting Pivot Tables\n",
    "\n",
    "**What this shows**:\n",
    "- Each row = combination of RM.bin and CHAS\n",
    "- `mean(MEDV)` = average median home value for that group\n",
    "\n",
    "**Business insight**: \n",
    "- More rooms ‚Üí Higher median value (as expected)\n",
    "- River proximity (CHAS=1) ‚Üí Premium pricing\n",
    "\n",
    "### Creating Cross-Tabulated Pivot Tables\n",
    "\n",
    "Use `reshape` package for traditional Excel-style pivot tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e47cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(reshape)\n",
    "boston.housing.df <- mlba::BostonHousing\n",
    "# create bins of size 1\n",
    "boston.housing.df <- boston.housing.df %>%\n",
    "  mutate(RM.bin = cut(RM, c(1:9), labels=FALSE))\n",
    "\n",
    "# use melt() to stack a set of columns into a single column of data.\n",
    "# stack MEDV values for each combination of (binned) RM and CHAS\n",
    "mlt <- melt(boston.housing.df, id=c(\"RM.bin\", \"CHAS\"), measure=c(\"MEDV\"))\n",
    "head(mlt, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07563ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cast() to reshape data and generate pivot table\n",
    "cast(mlt, RM.bin ~ CHAS, subset=variable==\"MEDV\",\n",
    "     margins=c(\"grand_row\", \"grand_col\"), mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a69b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidyverse version (simpler and more readable)\n",
    "boston.housing.df %>%\n",
    "  group_by(RM.bin, CHAS) %>%\n",
    "  summarize(mean=mean(MEDV)) %>%\n",
    "  spread(CHAS, mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa764c1",
   "metadata": {},
   "source": [
    "### üìã Reading Pivot Tables\n",
    "\n",
    "**Structure**:\n",
    "- **Rows**: RM.bin (number of rooms category)\n",
    "- **Columns**: CHAS (0 = no river, 1 = river)\n",
    "- **Values**: Average MEDV (median home value in $1000s)\n",
    "\n",
    "**Business application**: This is exactly how you'd analyze:\n",
    "- Sales by Region √ó Product Category\n",
    "- Customer satisfaction by Store √ó Service Type\n",
    "- Revenue by Quarter √ó Sales Channel\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9091f49",
   "metadata": {},
   "source": [
    "## Part 3: Reducing Categories in Categorical Variables\n",
    "\n",
    "### üè¢ Business Context: Simplification for Clarity\n",
    "\n",
    "Sometimes categorical variables have **too many levels**:\n",
    "- 50 states ‚Üí Regions (Northeast, South, Midwest, West)\n",
    "- 100 product SKUs ‚Üí Product families\n",
    "- 20 age groups ‚Üí Young/Middle/Senior\n",
    "\n",
    "**Benefits**:\n",
    "- Easier interpretation for stakeholders\n",
    "- More stable models (avoid overfitting)\n",
    "- Clearer visualizations\n",
    "\n",
    "### Visualizing Category Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205201ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.housing.df <- mlba::BostonHousing\n",
    "\n",
    "tbl <- table(boston.housing.df$CAT.MEDV, boston.housing.df$ZN)\n",
    "prop.tbl <- prop.table(tbl, margin=2)\n",
    "barplot(prop.tbl, xlab=\"ZN\", ylab=\"\", yaxt=\"n\",main=\"Distribution of CAT.MEDV by ZN\")\n",
    "axis(2, at=(seq(0,1, 0.2)), paste(seq(0,100,20), \"%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fded95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ggplot2 version (publication quality)\n",
    "library(tidyverse)\n",
    "df <- data.frame(prop.tbl)\n",
    "ggplot(df, aes(x=Var2, y=Freq, group=Var1, fill=Var1)) +\n",
    "  geom_bar(stat=\"identity\", color=\"grey\", width=1) +\n",
    "  scale_y_continuous(labels = scales::percent, expand=expansion()) +\n",
    "  scale_fill_manual(\"CAT.MEDV\", values=c(\"0\"=\"#eeeeee\", \"1\"=\"darkgrey\")) +\n",
    "  labs(x=\"ZN\", y=\"\", title=\"Distribution of CAT.MEDV by ZN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b408693",
   "metadata": {},
   "source": [
    "### üìã Interpreting Stacked Bar Charts\n",
    "\n",
    "**What you see**:\n",
    "- Each bar = 100% (one ZN category)\n",
    "- Dark section = proportion with CAT.MEDV = 1 (high value)\n",
    "- Light section = proportion with CAT.MEDV = 0 (low value)\n",
    "\n",
    "**Business insight**: If ZN has many categories with similar distributions, consider collapsing them.\n",
    "\n",
    "### Time Series Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(forecast)\n",
    "tru.data <- mlba::ToysRUsRevenues\n",
    "tru.ts <- ts(tru.data[, 3], start = c(1992, 1), end = c(1995, 4), freq = 4)\n",
    "autoplot(tru.ts) +\n",
    "  geom_point(size=0.5) +\n",
    "  labs(x=\"Time\", y=\"Revenue ($ millions)\") +\n",
    "  theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da937bd2",
   "metadata": {},
   "source": [
    "### üìã Time Series Visualization\n",
    "\n",
    "**Patterns to look for**:\n",
    "- **Trend**: Overall upward/downward movement\n",
    "- **Seasonality**: Regular patterns (Q4 spikes for retail)\n",
    "- **Outliers**: Unusual points (promotions, disruptions)\n",
    "\n",
    "**Business application**: Forecast future revenues, plan inventory.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26c4573",
   "metadata": {},
   "source": [
    "## Part 4: Principal Components Analysis (PCA)\n",
    "\n",
    "### üè¢ Business Context: The Curse of Dimensionality\n",
    "\n",
    "**Problem**: Your customer dataset has 100 variables. Which ones matter?\n",
    "\n",
    "**PCA Solution**: Reduces 100 correlated variables to 5-10 **principal components** that capture most of the variation.\n",
    "\n",
    "### How PCA Works\n",
    "\n",
    "```\n",
    "ORIGINAL DATA                    PCA TRANSFORMATION\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ 50 correlated   ‚îÇ     ‚Üí       ‚îÇ 5 uncorrelated  ‚îÇ\n",
    "‚îÇ variables       ‚îÇ             ‚îÇ components      ‚îÇ\n",
    "‚îÇ (multicollinear)‚îÇ             ‚îÇ (independent)   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "      Hard to                      Easy to\n",
    "    interpret                     interpret\n",
    "```\n",
    "\n",
    "**Key benefits**:\n",
    "1. **Dimension reduction**: 50 ‚Üí 5 variables\n",
    "2. **Removes multicollinearity**: Components are orthogonal (uncorrelated)\n",
    "3. **Noise reduction**: Minor components capture noise, not signal\n",
    "\n",
    "### Example 2: Breakfast Cereals\n",
    "\n",
    "Start with a simple 2-variable example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ead6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "cereals.df <- mlba::Cereals %>% select(calories, rating)\n",
    "# compute PCs on two dimensions\n",
    "pcs <- prcomp(cereals.df %>% select(calories, rating))\n",
    "summary(pcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f9836e",
   "metadata": {},
   "source": [
    "### üìã Interpreting PCA Summary\n",
    "\n",
    "**Key metrics**:\n",
    "- **Standard deviation**: Spread of data along each component\n",
    "- **Proportion of Variance**: % of total variability explained\n",
    "- **Cumulative Proportion**: Running total of variance explained\n",
    "\n",
    "**Example interpretation**:\n",
    "- PC1 explains 96% of variance ‚Üí Captures almost all information\n",
    "- PC2 explains 4% ‚Üí Minor patterns, possibly noise\n",
    "\n",
    "### Principal Component Loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0137d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs$rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01ae5bb",
   "metadata": {},
   "source": [
    "### üìã Understanding Loadings\n",
    "\n",
    "**Loadings** show how original variables combine to form components:\n",
    "\n",
    "```\n",
    "PC1 = (0.685 √ó calories) + (0.729 √ó rating)\n",
    "PC2 = (0.729 √ó calories) + (-0.685 √ó rating)\n",
    "```\n",
    "\n",
    "**Interpretation**:\n",
    "- **High positive loading**: Variable strongly contributes in same direction\n",
    "- **High negative loading**: Variable contributes in opposite direction\n",
    "- **Near-zero loading**: Variable doesn't contribute to this component\n",
    "\n",
    "### Component Scores\n",
    "\n",
    "Each observation gets a score on each component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores <- pcs$x\n",
    "head(scores, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93639d96",
   "metadata": {},
   "source": [
    "### üìã Using Component Scores\n",
    "\n",
    "**What scores mean**:\n",
    "- Each cereal has a PC1 score and PC2 score\n",
    "- Use these scores as new features in downstream models\n",
    "- Scores are **uncorrelated** ‚Üí no multicollinearity!\n",
    "\n",
    "### Visualizing Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d0c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "getPCaxis <- function(f, pcs, pcLabel) {\n",
    "  return (data.frame(\n",
    "    rbind(pcs$center + f * pcs$rotation[, pcLabel],\n",
    "          pcs$center - f * pcs$rotation[, pcLabel]))\n",
    "  )\n",
    "}\n",
    "PC1 <- getPCaxis(90, pcs, \"PC1\")\n",
    "PC2 <- getPCaxis(50, pcs, \"PC2\")\n",
    "ggplot(cereals.df, aes(x=calories, y=rating)) +\n",
    "  geom_point() +\n",
    "  geom_line(data=PC1) +\n",
    "  geom_line(data=PC2) +\n",
    "  coord_cartesian(xlim=c(0, 200), ylim=c(0, 110)) +\n",
    "  labs(x=\"Calories\", y=\"Rating\") +\n",
    "  annotate(geom=\"text\", x=30, y=80, label=\"z[1]\",parse=TRUE) +\n",
    "  annotate(geom=\"text\", x=120, y=80, label=\"z[2]\",parse=TRUE) +\n",
    "  theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3627224b",
   "metadata": {},
   "source": [
    "### üìã Reading the PCA Plot\n",
    "\n",
    "**What you see**:\n",
    "- **Points**: Individual cereals\n",
    "- **Lines**: Principal component directions\n",
    "- **z‚ÇÅ (PC1)**: Direction of maximum variance\n",
    "- **z‚ÇÇ (PC2)**: Orthogonal direction (90¬∞ to PC1)\n",
    "\n",
    "**Business insight**: PC1 captures the main pattern, PC2 captures residual variation.\n",
    "\n",
    "---\n",
    "\n",
    "### Full PCA on All Cereal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and preprocess the data\n",
    "cereals.df <- mlba::Cereals %>%\n",
    "  column_to_rownames(\"name\") %>%\n",
    "  select(-c(mfr, type)) %>%\n",
    "  drop_na()\n",
    "\n",
    "pcs <- prcomp(cereals.df)\n",
    "summary(pcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd0caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs$rotation[,1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b450610",
   "metadata": {},
   "source": [
    "### üìã Interpreting Multi-Variable PCA\n",
    "\n",
    "**How many components to keep?**\n",
    "\n",
    "| Rule | Criterion |\n",
    "|------|----------|\n",
    "| **Cumulative variance** | Keep components explaining 80-90% of variance |\n",
    "| **Scree plot** | Keep components before the \"elbow\" |\n",
    "| **Eigenvalue > 1** | Kaiser criterion (for standardized data) |\n",
    "\n",
    "**Business decision**: More components = more accuracy, but less interpretability.\n",
    "\n",
    "### ‚ö†Ô∏è Normalizing Data for PCA\n",
    "\n",
    "**Critical**: If variables have different scales, PCA will be dominated by large-scale variables!\n",
    "\n",
    "Example:\n",
    "- Calories (range: 50-150)\n",
    "- Sodium (range: 0-300)\n",
    "- Protein (range: 1-6)\n",
    "\n",
    "Sodium will dominate PC1 just because of its scale, not its importance.\n",
    "\n",
    "**Solution**: Use `scale. = TRUE` to standardize all variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdbab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use function prcomp() with scale. = T to run PCA on normalized data\n",
    "pcs.cor <- prcomp(cereals.df, scale. = T)\n",
    "\n",
    "summary(pcs.cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e974cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs.cor$rotation[,1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e378f9ab",
   "metadata": {},
   "source": [
    "### üìã Normalized vs. Non-Normalized PCA\n",
    "\n",
    "**When to normalize:**\n",
    "- Variables on different scales (always normalize!)\n",
    "- You care about **correlations**, not raw variances\n",
    "\n",
    "**When NOT to normalize:**\n",
    "- All variables in same units (e.g., all are percentages)\n",
    "- Scale differences are meaningful (e.g., larger variance = more important)\n",
    "\n",
    "**Best practice**: Almost always use `scale. = TRUE` in business applications.\n",
    "\n",
    "### Visualizing Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa459ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggrepel)\n",
    "ggplot(data.frame(pcs.cor$x), aes(x=PC1, y=PC2, label=rownames(pcs.cor$x))) +\n",
    "  geom_point(shape=21) +\n",
    "  geom_text_repel(size=2, max.overlaps=7) +\n",
    "  theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f069e7",
   "metadata": {},
   "source": [
    "### üìã Interpreting the PCA Biplot\n",
    "\n",
    "**What you see**:\n",
    "- Each **point** = one cereal\n",
    "- **X-axis (PC1)**: First principal component (highest variance)\n",
    "- **Y-axis (PC2)**: Second principal component\n",
    "- **Proximity**: Cereals close together are similar\n",
    "\n",
    "**Business applications**:\n",
    "- **Market segmentation**: Clusters of similar products\n",
    "- **Outlier detection**: Points far from center\n",
    "- **Competitive analysis**: Which products compete directly?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad376c",
   "metadata": {},
   "source": [
    "## Part 5: Using PCA for Downstream Modeling\n",
    "\n",
    "### üè¢ Business Context: PCA as Preprocessing\n",
    "\n",
    "**Workflow**:\n",
    "1. Run PCA to reduce 50 variables to 10 components\n",
    "2. Use component scores as features in classification/regression\n",
    "3. Benefit from uncorrelated, de-noised features\n",
    "\n",
    "### Example: Wine Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf18b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.df <- mlba::Wine %>% select(-Type)\n",
    "pcs.cor <- prcomp(wine.df, scale. = TRUE)\n",
    "summary(pcs.cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9408d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs.cor$rotation[,1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dc8fff",
   "metadata": {},
   "source": [
    "### üìã Deciding How Many Components to Use\n",
    "\n",
    "**Example decision**:\n",
    "- Original: 13 variables\n",
    "- PC1-PC4 explain 73% of variance\n",
    "- PC1-PC6 explain 85% of variance\n",
    "\n",
    "**Trade-off**:\n",
    "- Fewer components ‚Üí Simpler model, less overfitting, easier interpretation\n",
    "- More components ‚Üí Better accuracy, captures more patterns\n",
    "\n",
    "**Common practice**: Start with components explaining 80-85% of variance.\n",
    "\n",
    "### üéØ Next Steps: Classification/Regression\n",
    "\n",
    "After PCA, you would:\n",
    "1. Extract component scores: `pcs.cor$x`\n",
    "2. Use them in models: `lm()`, `glm()`, `randomForest()`, etc.\n",
    "3. Evaluate performance on holdout set\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75229d60",
   "metadata": {},
   "source": [
    "## Summary: Key Takeaways\n",
    "\n",
    "### üîß Essential Functions Reference\n",
    "\n",
    "#### Data Summaries\n",
    "| Task | Function | Output |\n",
    "|------|----------|--------|\n",
    "| All statistics | `summary(df)` | Min, Q1, median, mean, Q3, max |\n",
    "| Mean | `mean(x)` | Average value |\n",
    "| Standard deviation | `sd(x)` | Measure of spread |\n",
    "| Correlation matrix | `cor(df)` | All pairwise correlations |\n",
    "\n",
    "#### Aggregation\n",
    "| Task | Function | Business Use |\n",
    "|------|----------|-------------|\n",
    "| Frequency table | `table(x)` | Count by category |\n",
    "| Group summaries | `group_by() %>% summarise()` | Averages by segment |\n",
    "| Pivot table | `spread()` or `cast()` | Cross-tabulation |\n",
    "\n",
    "#### Principal Component Analysis\n",
    "| Task | Function | Notes |\n",
    "|------|----------|-------|\n",
    "| Run PCA | `prcomp(df, scale.=TRUE)` | Always normalize! |\n",
    "| Summary | `summary(pcs)` | Variance explained |\n",
    "| Loadings | `pcs$rotation` | Variable contributions |\n",
    "| Scores | `pcs$x` | New feature values |\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Best Practices Checklist\n",
    "\n",
    "‚úÖ **Always check for missing values** before analysis\n",
    "‚úÖ **Compute correlations** to detect multicollinearity\n",
    "‚úÖ **Normalize data** (`scale.=TRUE`) before PCA unless all variables are on same scale\n",
    "‚úÖ **Check variance explained** to decide how many components to keep\n",
    "‚úÖ **Document your decisions** (why 5 components? why normalize?)\n",
    "‚úÖ **Visualize results** for stakeholders (biplots, scree plots)\n",
    "\n",
    "---\n",
    "\n",
    "### üè¢ Business Value Summary\n",
    "\n",
    "| Technique | Business Problem | Value |\n",
    "|-----------|------------------|-------|\n",
    "| **Summary statistics** | \"What does our data look like?\" | Quick insights, data quality checks |\n",
    "| **Pivot tables** | \"How do metrics vary by segment?\" | Targeted strategies, resource allocation |\n",
    "| **PCA** | \"Which variables really matter?\" | Simplified models, reduced storage costs |\n",
    "| **Dimension reduction** | \"Too many features for model\" | Prevent overfitting, faster computation |\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Connection to Other Modules\n",
    "\n",
    "- **Module 1.1**: Use PCA components as features in regression\n",
    "- **Module 2.1**: Test differences between PCA-derived groups (ANOVA)\n",
    "- **Module 3**: Advanced dimension reduction (t-SNE, UMAP)\n",
    "- **Module 4**: Factor Analysis (similar to PCA but different assumptions)\n",
    "- **Module 5**: Cluster on PCA scores instead of raw variables\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps**: Apply PCA to your own high-dimensional datasets. Start with `scale.=TRUE` and keep components explaining 80-90% of variance!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
